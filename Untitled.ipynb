{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "841a46a1-7349-4c64-a364-74d3bf16fc94",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m configure_logger\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# spaCyのモデルをロード\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men_core_web_sm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m configure_logger()\n\u001b[1;32m     13\u001b[0m logger \u001b[38;5;241m=\u001b[39m structlog\u001b[38;5;241m.\u001b[39mget_logger()\n",
      "File \u001b[0;32m~/dev/kasi-x/akizora/.venv/lib/python3.12/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/kasi-x/akizora/.venv/lib/python3.12/site-packages/spacy/util.py:472\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> 472\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import TypedDict\n",
    "\n",
    "import spacy\n",
    "import structlog\n",
    "from src.logger_config import configure_logger\n",
    "\n",
    "# spaCyのモデルをロード\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "configure_logger()\n",
    "logger = structlog.get_logger()\n",
    "\n",
    "\n",
    "class SentenceInfo(TypedDict):\n",
    "    text: str\n",
    "    token_count: int\n",
    "    chapter_number: int\n",
    "    chapter_title: str\n",
    "    section_number_in_chapter: int\n",
    "    section_number_in_text: int\n",
    "    is_chapter_title: bool\n",
    "\n",
    "\n",
    "class Chapter(TypedDict):\n",
    "    title: str\n",
    "    number: int\n",
    "    content: str\n",
    "\n",
    "\n",
    "def count_tokens(sentence: str) -> int:\n",
    "    \"\"\"Counts the number of tokens in a sentence.\"\"\"\n",
    "    return len(sentence.split())\n",
    "\n",
    "\n",
    "def clean_section_text(section: str) -> str:\n",
    "    \"\"\"Removes newline characters from a section and replaces them with spaces.\"\"\"\n",
    "    return section.replace(\"\\n\", \" \")\n",
    "\n",
    "\n",
    "def is_valid_chapter_title(text: str) -> bool:\n",
    "    return text.startswith(\"CHAPTER\") or (not text.endswith(\".\") and len(text) <= 20)\n",
    "\n",
    "\n",
    "def extract_title_and_sections(block: str) -> tuple[str, list[str]]:\n",
    "    parts = re.split(r\"\\n{2,}\", block, 1)\n",
    "    return (parts[0], parts[1:]) if len(parts) > 1 else (parts[0], [])\n",
    "\n",
    "\n",
    "class TextAnalyzer:\n",
    "    def __init__(self, text: str) -> None:\n",
    "        self.text = text\n",
    "        self.chapters: list[Chapter] = []\n",
    "        self.sentences_info: list[SentenceInfo] = []\n",
    "        self.current_chapter_number = 0\n",
    "        self.current_section_number_in_text = 0\n",
    "\n",
    "    def analyze_text(self) -> None:\n",
    "        logger.info(\"Start text analysis\")\n",
    "        chapter_blocks = self._extract_chapter_blocks()\n",
    "        self._analyze_chapter_blocks(chapter_blocks)\n",
    "\n",
    "    def _extract_chapter_blocks(self) -> list[str]:\n",
    "        return re.split(r\"\\n{3,}\", self.text.strip())\n",
    "\n",
    "    def _analyze_chapter_blocks(self, chapter_blocks: list[str]) -> None:\n",
    "        for block in chapter_blocks:\n",
    "            title, sections = extract_title_and_sections(block)\n",
    "            if is_valid_chapter_title(title):\n",
    "                self._increment_chapter()\n",
    "                self._analyze_sections(sections, title)\n",
    "            else:\n",
    "                self._analyze_sections([block], \"\")\n",
    "\n",
    "    def _increment_chapter(self) -> None:\n",
    "        self.current_chapter_number += 1\n",
    "\n",
    "    def _analyze_sections(self, sections: list[str], title: str) -> None:\n",
    "        section_number_in_chapter = 0\n",
    "        for section in sections:\n",
    "            section_number_in_chapter += 1\n",
    "            self._analyze_section(section, title, section_number_in_chapter)\n",
    "\n",
    "    def _analyze_section(\n",
    "        self, section: str, chapter_title: str, section_number_in_chapter: int\n",
    "    ) -> None:\n",
    "        cleaned_section = clean_section_text(section)\n",
    "        self._process_sentences_in_section(\n",
    "            cleaned_section, chapter_title, section_number_in_chapter\n",
    "        )\n",
    "\n",
    "    def _process_sentences_in_section(\n",
    "        self, section: str, chapter_title: str, section_number_in_chapter: int\n",
    "    ) -> None:\n",
    "        doc = nlp(section)\n",
    "        for sent in doc.sents:\n",
    "            self._store_sentence_info(sent.text, chapter_title, section_number_in_chapter)\n",
    "\n",
    "    def _store_sentence_info(\n",
    "        self, sentence: str, chapter_title: str, section_number_in_chapter: int\n",
    "    ) -> None:\n",
    "        self.current_section_number_in_text += 1\n",
    "        sentence_info = self._create_sentence_info(\n",
    "            sentence.strip(), chapter_title, section_number_in_chapter\n",
    "        )\n",
    "        self.sentences_info.append(sentence_info)\n",
    "\n",
    "    def _create_sentence_info(\n",
    "        self, sentence: str, chapter_title: str, section_number_in_chapter: int\n",
    "    ) -> SentenceInfo:\n",
    "        token_count = count_tokens(sentence)\n",
    "        return SentenceInfo(\n",
    "            text=sentence,\n",
    "            token_count=token_count,\n",
    "            chapter_number=self.current_chapter_number,\n",
    "            chapter_title=chapter_title,\n",
    "            section_number_in_chapter=section_number_in_chapter,\n",
    "            section_number_in_text=self.current_section_number_in_text,\n",
    "            is_chapter_title=chapter_title == sentence,\n",
    "        )\n",
    "\n",
    "    def save_to_json(self, file_path: str) -> None:\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(self.sentences_info, f, ensure_ascii=False, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa31864d-9567-4f16-a36a-97146a05d819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
