{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83f1c749-5818-40c9-89ba-3747e07405c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from dataclasses import field\n",
    "\n",
    "\n",
    "def remove_noise_space(text: str) -> str:\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def count_llm_tokens(text: str) -> int:\n",
    "    return len(text)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Sentence:\n",
    "    text: str\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.text = remove_noise_space(self.text)\n",
    "\n",
    "    @property\n",
    "    def token_count(self):\n",
    "        return len(self.text.split())\n",
    "\n",
    "    @property\n",
    "    def word_count(self):\n",
    "        return count_llm_tokens(self.text)\n",
    "\n",
    "    @property\n",
    "    def char_count(self):\n",
    "        return len(self.text)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Section:\n",
    "    sentences: list[Sentence] = field(default_factory=list)\n",
    "\n",
    "    @property\n",
    "    def token_count(self):\n",
    "        return sum(sentence.token_count for sentence in self.sentences)\n",
    "\n",
    "    @property\n",
    "    def word_count(self):\n",
    "        return sum(sentence.word_count for sentence in self.sentences)\n",
    "\n",
    "    @property\n",
    "    def char_count(self):\n",
    "        return sum(sentence.char_count for sentence in self.sentences)\n",
    "\n",
    "    @property\n",
    "    def sentences_count(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Chapter:\n",
    "    chapter_title: str = \"NO_TITLE\"\n",
    "    sections: list[Section] = field(default_factory=list)\n",
    "\n",
    "    @property\n",
    "    def token_count(self):\n",
    "        return sum(section.token_count for section in self.sections)\n",
    "\n",
    "    @property\n",
    "    def word_count(self):\n",
    "        return sum(section.word_count for section in self.sections)\n",
    "\n",
    "    @property\n",
    "    def char_count(self):\n",
    "        return sum(section.char_count for section in self.sections)\n",
    "\n",
    "    @property\n",
    "    def sentences_count(self):\n",
    "        return sum(section.sentences_count for section in self.sections)\n",
    "\n",
    "    @property\n",
    "    def sections_count(self):\n",
    "        return len(self.sections)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Book:\n",
    "    title: str = \"NO_TITLE\"\n",
    "    chapters: list[Chapter] = field(default_factory=list)\n",
    "\n",
    "    @property\n",
    "    def token_count(self):\n",
    "        return sum(chapter.token_count for chapter in self.chapters)\n",
    "\n",
    "    @property\n",
    "    def word_count(self):\n",
    "        return sum(chapter.word_count for chapter in self.chapters)\n",
    "\n",
    "    @property\n",
    "    def char_count(self):\n",
    "        return sum(chapter.char_count for chapter in self.chapters)\n",
    "\n",
    "    @property\n",
    "    def sentences_count(self):\n",
    "        return sum(chapter.sentences_count for chapter in self.chapters)\n",
    "\n",
    "    @property\n",
    "    def sections_count(self):\n",
    "        return sum(chapter.sections_count for chapter in self.chapters)\n",
    "\n",
    "    @property\n",
    "    def chapters_count(self):\n",
    "        return len(self.chapters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3becda1-0a34-4fe2-9327-40e54b8d1d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def replace_single_newlines(text: str) -> str:\n",
    "    \"\"\"テキスト内の単独の改行を空白に置換し、タグを含む行はそのまま保持する関数.\n",
    "    Some Book is inserted newline for A4 paper view, so it is not required to remove it.\n",
    "    \"\"\"\n",
    "    SINGLE_NEWLINE_PATTERN = re.compile(r\"(?<!\\n)\\n(?!\\n)\")\n",
    "\n",
    "    def is_tag_line(line):\n",
    "        \"\"\"行内にHTMLタグが存在するかを判定する関数.\"\"\"\n",
    "        return \"<\" in line and \">\" in line\n",
    "\n",
    "    def replace_single_newline_with_space(line):\n",
    "        \"\"\"単独の改行を空白に置換する関数.\"\"\"\n",
    "        return SINGLE_NEWLINE_PATTERN.sub(\" \", line)\n",
    "\n",
    "    lines = text.split(\"\\n\")\n",
    "    # HEADER tag is not so good, but it is convenient for now.\n",
    "    # In some case, it can be wrong.\n",
    "    lines.insert(0, \"<HEADER>\")\n",
    "\n",
    "    modified_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        if is_tag_line(line):\n",
    "            modified_lines.append(line)\n",
    "        else:\n",
    "            # NOTE: KEEP LEST DEPENDENT NEWLINE MAKR\n",
    "            \"\"\"if not alone newline mark, it would have meaning, not remove it.(sometime it is falte-positive)\n",
    "\n",
    "             hello/n world -> hello world\n",
    "             hello/n -> hello\n",
    "             hello/n/n/n -> hello/n/n/n # it may have meaning.\n",
    "             \"\"\"\n",
    "            line = replace_single_newline_with_space(line)\n",
    "            modified_lines.append(line)\n",
    "\n",
    "    return \"\\n\".join(modified_lines)\n",
    "\n",
    "\n",
    "def mark_sections(text: str) -> str:\n",
    "    lines = text.split(\"\\n\")\n",
    "    modified_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if re.match(r\"(?i)^CHAPTER\\s+\\d+\", line):\n",
    "            modified_lines.append(f\"<CHAPTER><CHAPTER_TITLE> {line} </CHAPTER_TITLE>\")\n",
    "        if re.match(r\"(?i)^PART\\s+\\d+\", line):\n",
    "            modified_lines.append(f\"<PART><PART_TITLE> {line} </PART_TITLE>\")\n",
    "        if re.match(r\"(?i)^EPILOGUE\", line):\n",
    "            modified_lines.append(f\"<EPILOGUE> {line}\")\n",
    "        if re.match(r\"^THE END$\", line):\n",
    "            modified_lines.append(f\"<THE_END> {line} </THE_END>\")\n",
    "        if re.match(r\"(?i)^OPENING\", line):\n",
    "            modified_lines.append(f\"<OPENING> {line}\")\n",
    "        if re.match(r\"(?i)^PROLOGUE\", line):\n",
    "            modified_lines.append(f\"<PROLOGUE><PROLOGUE_TITLE> {line} </PROLOGUE_TITLE>\")\n",
    "        if re.match(r\"(?i)^TRANSCRIBER NOTES\", line):\n",
    "            modified_lines.append(f\"<TRANSCRIBER_NOTES> {line} \")\n",
    "        else:\n",
    "            modified_lines.append(line)\n",
    "\n",
    "    return \"\\n\".join(modified_lines)\n",
    "\n",
    "\n",
    "def auto_close_tags(text: str) -> str:\n",
    "    # FUTURE: expand this priority later.\n",
    "    \"\"\"Maybe more priority is required later and in some special book.\n",
    "    this priority is just for idea for me.\n",
    "    for example, PART vs EPIOLOGUE, which is more important?\n",
    "    In some book, each part has epilogue, so PART can be more important.\n",
    "    \"\"\"\n",
    "    priority = {\n",
    "        \"PART\": 3,\n",
    "        \"CHAPTER\": 2,\n",
    "        \"TRANSCRIBER_NOTES\": 4,\n",
    "        \"THE_END\": 1,\n",
    "        \"EPILOGUE\": 4,\n",
    "        \"PROLOGUE\": 4,\n",
    "        \"DATA\": 1,\n",
    "        \"HEADER\": 2,\n",
    "    }\n",
    "    priority = dict(sorted(priority.items(), key=lambda item: item[1]))\n",
    "\n",
    "    def sort_tags(tags):\n",
    "        return sorted(tags, key=lambda tag: priority.get(tag, -1))\n",
    "\n",
    "    def get_priority(tag):\n",
    "        return priority.get(tag, -1)\n",
    "\n",
    "    # Not yet used que. But you should change this to que.\n",
    "    living_tag_stack = []\n",
    "    contents = []\n",
    "    remove_list = []\n",
    "\n",
    "    tag_pattern = re.compile(r\"</?([A-Z_]+)>\")\n",
    "\n",
    "    lines = text.split(\"\\n\")\n",
    "\n",
    "    # REFACTOR: make more readable this function by separating into functions.\n",
    "    for line in lines:\n",
    "        tags_found = tag_pattern.findall(line)\n",
    "        for new_tag in tags_found:\n",
    "            start_tag = f\"<{new_tag}>\"\n",
    "            end_tag = f\"</{new_tag}>\"\n",
    "            if start_tag in line:\n",
    "                if living_tag_stack:\n",
    "                    for open_tag in living_tag_stack:\n",
    "                        if get_priority(open_tag) <= get_priority(new_tag):\n",
    "                            # OPTIMIZE: rewrite for change algorithm.\n",
    "                            \"\"\"Use stack and pop and change this algorithm.\n",
    "                            We can use html tag relate idea. Never happen '<t><a> </t></a>', close tag must be in order.\n",
    "                            In other words, when stack is '<chapter><hoge>' and </chapeter> event happend, <hoge> must be closed at previous point of close chapter.\n",
    "                            Be careful to keep passing test case.\n",
    "                            \"\"\"\n",
    "\n",
    "                            contents.append(f\"</{open_tag}>\")\n",
    "                            remove_list.append(open_tag)\n",
    "                    living_tag_stack = [\n",
    "                        new_tag for new_tag in living_tag_stack if new_tag not in remove_list\n",
    "                    ]\n",
    "                    remove_list = []\n",
    "                living_tag_stack.append(new_tag)\n",
    "                living_tag_stack = sort_tags(living_tag_stack)\n",
    "\n",
    "            if end_tag in line:\n",
    "                living_tag_stack.remove(new_tag)\n",
    "                if living_tag_stack:  # POINTLESS: not required. Because for loop is not executed when living_tag_stack is empty.\n",
    "                    for open_tag in living_tag_stack:\n",
    "                        if get_priority(open_tag) <= get_priority(new_tag):\n",
    "                            contents.append(f\"</{open_tag}>\")\n",
    "                            remove_list.append(open_tag)\n",
    "                    living_tag_stack = [\n",
    "                        new_tag for new_tag in living_tag_stack if new_tag not in remove_list\n",
    "                    ]\n",
    "                    remove_list = []\n",
    "        contents.append(line)\n",
    "\n",
    "    while living_tag_stack:\n",
    "        contents.append(f\"</{living_tag_stack.pop()}>\")\n",
    "\n",
    "    return \"\\n\".join(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca23109d-69d0-4f92-b998-f7a3cd8353d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "file = \"horizon_trial/sample.txt\"\n",
    "text = open(file).read()\n",
    "marked_text = mark_sections(text)\n",
    "#pprint(marked_text)\n",
    "marked_space_removed_text = replace_single_newlines(marked_text)\n",
    "#pprint(marked_space_removed_text)\n",
    "auto_closed_text = auto_close_tags(marked_space_removed_text)\n",
    "#pprint(auto_closed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "866ed7e9-22dc-4822-ae4e-c7008ee6f7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter Title: NO_TITLE, Sentences: 3, Sections: 1\n",
      "Chapter Title: NO_TITLE, Sentences: 3, Sections: 1\n",
      "Chapter Title: NO_TITLE, Sentences: 28, Sections: 1\n",
      "Chapter Title: NO_TITLE, Sentences: 34, Sections: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "# Assuming previous class definitions for Sentence, Section, Chapter, Book\n",
    "\n",
    "def remove_tags(text: str) -> str:\n",
    "    \"\"\"Remove HTML tags from a string.\"\"\"\n",
    "    return re.sub(r'<[^>]*>', '', text)\n",
    "\n",
    "def parse_book(text: str) -> Book:\n",
    "    parts = re.split(r'(<[^>]+>)', text)\n",
    "    chapters = []\n",
    "    current_chapter = Chapter()\n",
    "    current_section = Section()\n",
    "    title = \"NO_TITLE\"\n",
    "    in_header = True\n",
    "\n",
    "    for part in parts:\n",
    "        if part.strip() == '':\n",
    "            continue\n",
    "\n",
    "        # Handle header as the first non-tag text\n",
    "        if in_header and not part.startswith('<'):\n",
    "            title = remove_tags(part).strip()\n",
    "            in_header = False\n",
    "            continue\n",
    "\n",
    "        if part == '<CHAPTER>' or part == '<PROLOGUE>' or part == '<EPILOGUE>':\n",
    "            if current_section.sentences:\n",
    "                current_chapter.sections.append(current_section)\n",
    "            current_section = Section()\n",
    "            if current_chapter.sections:\n",
    "                chapters.append(current_chapter)\n",
    "            current_chapter = Chapter()\n",
    "            continue\n",
    "\n",
    "        if '<CHAPTER_TITLE>' in part or '<PROLOGUE_TITLE>' in part:\n",
    "            # Ensure to capture only the content within the title tags\n",
    "            title_match = re.search(r'>([^<]+)<', part)\n",
    "            if title_match:\n",
    "                chapter_title = title_match.group(1).strip()\n",
    "                current_chapter.chapter_title = chapter_title\n",
    "            continue\n",
    "\n",
    "        if part.startswith('<') and part.endswith('>'):\n",
    "            continue  # Skip standalone tags\n",
    "\n",
    "        # Handling content\n",
    "        sentences = [Sentence(text=remove_tags(sentence).strip()) for sentence in part.split('\\n') if sentence.strip()]\n",
    "        current_section.sentences.extend(sentences)\n",
    "\n",
    "    # Ensure the last chapter and section are added\n",
    "    if current_section.sentences:\n",
    "        current_chapter.sections.append(current_section)\n",
    "    if current_chapter.sections:\n",
    "        chapters.append(current_chapter)\n",
    "\n",
    "    return Book(title=title, chapters=chapters)\n",
    "\n",
    "\n",
    "book = parse_book(auto_closed_text)\n",
    "# print(f\"Book Title: {book.title}\")\n",
    "for chapter in book.chapters:\n",
    "    print(f\"Chapter Title: {chapter.chapter_title}, Sentences: {chapter.sentences_count}, Sections: {chapter.sections_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65418829-3ccd-4ab4-89a9-9f13428d27ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Book(title=\"=* A Distributed Proofreaders Canada eBook *=\\n\\nThis ebook is made available at no cost and with very few restrictions.\\n\\n_Title:_ Lost Horizon\\n_Date of first publication:_ 1936\\n_Author:_ James Hilton (1900-1954)\\n_Date first posted:_ Nov. 6, 2018\\n_Date last updated:_ Nov. 6, 2018\\nFaded Page eBook #20181110\\n\\n\\n\\n\\n\\n\\n\\n[Cover Illustration]\\n\\n\\n\\n\\n\\n\\nNOVELS BY JAMES HILTON\\n————\\nAND NOW GOODBYE\\nCONTANGO\\nKNIGHT WITHOUT ARMOUR\\nMURDER AT SCHOOL\\nCATHERINE HERSELF\\nTHE SILVER FLAME\\n\\n\\n\\n\\n\\n\\nL O S T   H O R I Z O N\\n\\n\\n\\nBY\\nJAMES HILTON\\n\\nMACMILLAN  AND  CO.,  LIMITED\\nST.  MARTIN'S  STREET,  LONDON\\n1936\\n\\n\\n\\n\\nCOPYRIGHT\\n\\n_First published 1933_\\n_The Cottage Library 1936_\\n\\n\\nPRINTED IN GREAT BRITAIN\\nBY R. & R. CLARK, LIMITED, EDINBURGH\", chapters=[Chapter(chapter_title='NO_TITLE', sections=[Section(sentences=[Sentence(text='PROLOGUE'), Sentence(text='PROLOGUE'), Sentence(text='Cigars had burned low, and we were beginning to sample the disillusionment...')])]), Chapter(chapter_title='NO_TITLE', sections=[Section(sentences=[Sentence(text='CHAPTER 1'), Sentence(text='CHAPTER 1'), Sentence(text='During that third week of May the situation in Baskul had become much worse...')])]), Chapter(chapter_title='NO_TITLE', sections=[Section(sentences=[Sentence(text='CHAPTER 2'), Sentence(text='CHAPTER 2'), Sentence(text='The journey was expected to be long and perilous...'), Sentence(text='gave him a most charming smile, but her eyes were all for the boy.'), Sentence(text='“What life?”'), Sentence(text='“The life you’re thinking of . . . dinners . . . dances . . . polo . . .'), Sentence(text='all that. . . .”'), Sentence(text='“But I never said anything about dances and polo! Anyhow, what’s wrong'), Sentence(text='with them? D’you mean that you’re not coming with me? You’re going to'), Sentence(text='stay here like the other two? Then at least you shan’t stop _me_ from'), Sentence(text='clearing out of it!” Mallinson threw down his cigarette and sprang'), Sentence(text='towards the door with eyes blazing. “You’re off your head!” he cried'), Sentence(text='wildly. “You’re mad, Conway, that’s what’s the matter with you! I know'), Sentence(text='you’re always calm, and I’m always excited, but I’m sane, at any rate,'), Sentence(text='and you’re not! They warned me about it before I joined you at Baskul,'), Sentence(text='and I thought they were wrong, but now I can see they weren’t——”'), Sentence(text='“To Lo-Tsen?”'), Sentence(text='“Yes, if you want to know.”'), Sentence(text='Conway got up and held out his hand. “Good-bye, Mallinson.”'), Sentence(text='“For the last time, you’re not coming?”'), Sentence(text='“I can’t.”'), Sentence(text='“Good-bye, then.”'), Sentence(text='They shook hands, and Mallinson left.'), Sentence(text='Conway sat alone in the lantern-light. It seemed to him, in a phrase'), Sentence(text='engraved on memory, that all the loveliest things were transient and'), Sentence(text='perishable, that the two worlds were finally beyond reconciliation, and'), Sentence(text='that one of them hung, as always, by a thread. After he had pondered for'), Sentence(text='some time he looked at his watch; it was ten minutes to three.')])]), Chapter(chapter_title='NO_TITLE', sections=[Section(sentences=[Sentence(text='EPILOGUE'), Sentence(text='EPILOGUE'), Sentence(text='IT WAS in Delhi that I met Rutherford again. We had been guests at a'), Sentence(text='Viceregal dinner-party, but distance and ceremonial kept us apart until'), Sentence(text='the turbaned flunkeys handed us our hats afterwards. “Come back to my'), Sentence(text='hotel and have a drink,” he invited.'), Sentence(text='“You thought it might be easier to look for the valley of Blue Moon?”'), Sentence(text='“Well, it did seem as if it might be a more fixed proposition. I suppose'), Sentence(text='you glanced at that manuscript of mine?”'), Sentence(text='“Much more than glanced at it. I should have returned it, by the way,'), Sentence(text='but you left no address.”'), Sentence(text='Rutherford nodded. “I wonder what you made of it?”'), Sentence(text='Rutherford flicked his cigar as if the narration had excited him quite'), Sentence(text='as much as he hoped it had me. Continuing, he said: “The little fellow'), Sentence(text='looked at me solemnly for a moment, and then answered in that funny'), Sentence(text='clipped English that the educated Chinese have—‘Oh no, she was most'), Sentence(text='old—most old of anyone I have ever seen.’”'), Sentence(text='We sat for a long time in silence, and then talked again of Conway as I'), Sentence(text='remembered him, boyish and gifted and full of charm, and of the War that'), Sentence(text='had altered him, and of so many mysteries of time and age and of the'), Sentence(text='mind, and of the little Manchu who had been ‘most old,’ and of the'), Sentence(text='strange ultimate dream of Blue Moon. “Do you think he will ever find'), Sentence(text='it?” I asked.'), Sentence(text='WOODFORD GREEN'), Sentence(text='April 1933'), Sentence(text='THE END'), Sentence(text='THE END'), Sentence(text='_Printed in Great Britain by_ R. & R. CLARK, LIMITED, _Edinburgh_.'), Sentence(text='TRANSCRIBER NOTES'), Sentence(text='Misspelled words and printer errors have been corrected. Where multiple'), Sentence(text='spellings occur, majority use has been employed.'), Sentence(text='Punctuation has been maintained except where obvious printer errors'), Sentence(text='occur.'), Sentence(text='[The end of _Lost Horizon_ by James Hilton]')])])])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8d02c8b-17e9-464b-8852-4dada6a258d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chapter(chapter_title='NO_TITLE', sections=[Section(sentences=[Sentence(text='PROLOGUE'), Sentence(text='PROLOGUE'), Sentence(text='Cigars had burned low, and we were beginning to sample the disillusionment...')])])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book.chapters[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61543ad-c155-4282-a7d2-14b25e43d291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
